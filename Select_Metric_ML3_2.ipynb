{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Оптимальная метрика\n",
        "\n",
        "В этом задании Вам предлагается подобрать оптимальную метрику и оптимальное значение гиперпараметра K из диапазона [1,50] для решения задачи классификации на примере датасета Ирисов Фишера. Этот датасет можно загрузить из модуля sklearn.datasets.\n",
        "\n",
        "Качества оценивается при помощи метрики accuracy при помощи методики кросс-валидации. Об этой методике можно подробнее прочитать в [документации sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html).\n",
        "\n",
        "Мы предлагаем Вам заполнить недостающие команды в следующем скелете кода и разобраться, какую метрику оптимально применять для решения данной задачи. В ответе на задание необходимо указать эту метрику.\n",
        "\n",
        "Попробуйте 3 варианта: манхэттенское расстояние, евклидово расстояние и косинусное расстояние. Полный список возможных метрик можно посмотреть по [ссылке](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.distance_metrics.html#sklearn.metrics.pairwise.distance_metrics). Меняйте этот параметр, изменяя значение аргумента `metric` при создании объекта класса `KNeighborsClassifier`. Найдите пару \"метрика\"-\"K\", для которой получается наилучшее качество и в качестве ответа укажите **найденную метрику**\n",
        "\n",
        "**Замечание**: параметр *n_splits* - это количество разбиений `cv` в кросс-валидации. В качестве итоговой метрики берётся усреднение полученных значений метрик по всем разбиениям."
      ],
      "metadata": {
        "id": "Vul_oMFvIqYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "random_seed = 4238\n",
        "\n",
        "np.random.seed(random_seed)\n",
        "n_splits = 3\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "\"\"\"\n",
        "  Здесь Вам предлагается написать тело цикла для подбора оптимального K\n",
        "  Результаты оценки алгоритма при каждом отдельно взятом K рекомендуем записывать в список cv_scores\n",
        "\"\"\"\n",
        "metrics = ['manhattan', 'euclidean', 'cosine']\n",
        "cv_scores = []\n",
        "for k in range(1, 51):\n",
        "    for metric in metrics:\n",
        "      clf = KNeighborsClassifier(n_neighbors=k, metric=metric)\n",
        "      scores = cross_val_score(clf, X, y, cv=5, scoring=\"accuracy\")\n",
        "      cv_scores += [[scores.mean(), metric, k]]\n",
        "cv_scores.sort(key=lambda res: res[0], reverse=True)\n",
        "print(cv_scores)\n"
      ],
      "metadata": {
        "id": "G9zTXC4TIsoG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26c1bc37-d1cf-4a9c-87d6-2b4b0d780a91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.9800000000000001, 'cosine', 3], [0.9800000000000001, 'cosine', 4], [0.9800000000000001, 'cosine', 5], [0.9800000000000001, 'euclidean', 6], [0.9800000000000001, 'euclidean', 7], [0.9800000000000001, 'euclidean', 10], [0.9800000000000001, 'manhattan', 11], [0.9800000000000001, 'euclidean', 11], [0.9800000000000001, 'manhattan', 12], [0.9800000000000001, 'euclidean', 12], [0.9800000000000001, 'cosine', 17], [0.9800000000000001, 'cosine', 19], [0.9800000000000001, 'cosine', 20], [0.9800000000000001, 'cosine', 22], [0.9800000000000001, 'cosine', 35], [0.9733333333333334, 'euclidean', 4], [0.9733333333333334, 'euclidean', 5], [0.9733333333333334, 'cosine', 6], [0.9733333333333334, 'manhattan', 7], [0.9733333333333334, 'cosine', 8], [0.9733333333333334, 'manhattan', 9], [0.9733333333333334, 'euclidean', 9], [0.9733333333333334, 'manhattan', 10], [0.9733333333333334, 'manhattan', 13], [0.9733333333333334, 'euclidean', 13], [0.9733333333333334, 'cosine', 13], [0.9733333333333334, 'manhattan', 14], [0.9733333333333334, 'cosine', 14], [0.9733333333333334, 'manhattan', 15], [0.9733333333333334, 'cosine', 15], [0.9733333333333334, 'manhattan', 16], [0.9733333333333334, 'cosine', 18], [0.9733333333333334, 'manhattan', 19], [0.9733333333333334, 'manhattan', 20], [0.9733333333333334, 'manhattan', 21], [0.9733333333333334, 'cosine', 21], [0.9733333333333334, 'cosine', 23], [0.9733333333333334, 'cosine', 24], [0.9733333333333334, 'cosine', 25], [0.9733333333333334, 'cosine', 26], [0.9733333333333334, 'cosine', 27], [0.9733333333333334, 'cosine', 28], [0.9733333333333334, 'cosine', 30], [0.9733333333333334, 'cosine', 31], [0.9733333333333334, 'cosine', 34], [0.9733333333333334, 'cosine', 36], [0.9733333333333334, 'cosine', 37], [0.9733333333333334, 'cosine', 38], [0.9733333333333334, 'cosine', 39], [0.9733333333333334, 'cosine', 41], [0.9733333333333334, 'cosine', 43], [0.9733333333333334, 'cosine', 44], [0.9733333333333334, 'cosine', 45], [0.9733333333333334, 'cosine', 46], [0.9733333333333334, 'cosine', 47], [0.9733333333333334, 'cosine', 48], [0.9666666666666668, 'euclidean', 3], [0.9666666666666668, 'euclidean', 8], [0.9666666666666668, 'cosine', 9], [0.9666666666666668, 'cosine', 10], [0.9666666666666668, 'cosine', 11], [0.9666666666666668, 'cosine', 12], [0.9666666666666668, 'euclidean', 15], [0.9666666666666668, 'euclidean', 16], [0.9666666666666668, 'cosine', 16], [0.9666666666666668, 'euclidean', 17], [0.9666666666666668, 'euclidean', 19], [0.9666666666666668, 'euclidean', 21], [0.9666666666666668, 'cosine', 29], [0.9666666666666668, 'cosine', 32], [0.9666666666666668, 'cosine', 33], [0.9666666666666668, 'cosine', 40], [0.9666666666666668, 'cosine', 42], [0.9666666666666668, 'cosine', 49], [0.9666666666666668, 'cosine', 50], [0.9666666666666666, 'euclidean', 14], [0.9666666666666666, 'manhattan', 17], [0.9666666666666666, 'euclidean', 18], [0.9600000000000002, 'manhattan', 5], [0.96, 'manhattan', 1], [0.96, 'euclidean', 1], [0.96, 'cosine', 1], [0.96, 'manhattan', 3], [0.96, 'cosine', 7], [0.96, 'manhattan', 18], [0.96, 'euclidean', 20], [0.96, 'manhattan', 22], [0.96, 'euclidean', 22], [0.96, 'manhattan', 23], [0.96, 'euclidean', 23], [0.96, 'manhattan', 25], [0.96, 'euclidean', 25], [0.96, 'manhattan', 28], [0.9533333333333334, 'cosine', 2], [0.9533333333333334, 'manhattan', 4], [0.9533333333333334, 'manhattan', 6], [0.9533333333333334, 'manhattan', 8], [0.9533333333333334, 'manhattan', 24], [0.9533333333333334, 'manhattan', 27], [0.9533333333333334, 'manhattan', 34], [0.9533333333333334, 'euclidean', 34], [0.9533333333333334, 'euclidean', 35], [0.9533333333333334, 'manhattan', 36], [0.9533333333333334, 'euclidean', 36], [0.9466666666666667, 'euclidean', 24], [0.9466666666666667, 'euclidean', 27], [0.9466666666666667, 'manhattan', 29], [0.9466666666666667, 'manhattan', 35], [0.9466666666666667, 'manhattan', 37], [0.9466666666666667, 'euclidean', 37], [0.9466666666666667, 'manhattan', 38], [0.9466666666666667, 'manhattan', 39], [0.9466666666666667, 'manhattan', 40], [0.9466666666666667, 'manhattan', 41], [0.9466666666666667, 'manhattan', 45], [0.9466666666666665, 'euclidean', 2], [0.9466666666666665, 'manhattan', 26], [0.9466666666666665, 'euclidean', 26], [0.9466666666666665, 'euclidean', 32], [0.9400000000000001, 'manhattan', 30], [0.9400000000000001, 'manhattan', 31], [0.9400000000000001, 'euclidean', 39], [0.9400000000000001, 'euclidean', 41], [0.9400000000000001, 'euclidean', 42], [0.9400000000000001, 'euclidean', 43], [0.9400000000000001, 'euclidean', 45], [0.9400000000000001, 'euclidean', 49], [0.9399999999999998, 'euclidean', 28], [0.9399999999999998, 'euclidean', 30], [0.9399999999999998, 'manhattan', 33], [0.9399999999999998, 'euclidean', 33], [0.9399999999999998, 'manhattan', 42], [0.9399999999999998, 'manhattan', 43], [0.9399999999999998, 'manhattan', 44], [0.9333333333333333, 'euclidean', 38], [0.9333333333333333, 'euclidean', 46], [0.9333333333333333, 'manhattan', 47], [0.9333333333333332, 'manhattan', 2], [0.9333333333333332, 'euclidean', 29], [0.9333333333333332, 'euclidean', 31], [0.9333333333333332, 'manhattan', 32], [0.9266666666666667, 'euclidean', 40], [0.9266666666666667, 'euclidean', 44], [0.9266666666666667, 'euclidean', 47], [0.9266666666666667, 'euclidean', 48], [0.9266666666666665, 'manhattan', 46], [0.9266666666666665, 'manhattan', 50], [0.9200000000000002, 'manhattan', 49], [0.9199999999999999, 'manhattan', 48], [0.9133333333333334, 'euclidean', 50]]\n"
          ]
        }
      ]
    }
  ]
}