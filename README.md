# MSU-ML-IFC

This repository is devoted to **Machine Learning MSU inter-faculty course**.

# ðŸ“š Overview of the Machine Learning Course  
The course covers fundamental and advanced topics in machine learning (ML), combining theory and practice. The material is structured around key areas:

---

## 1. **Fundamentals of Machine Learning**  
- **Introduction to ML**:  
  Definition of tasks (classification, regression, clustering), types of learning (supervised, unsupervised), general workflow (data â†’ model â†’ evaluation).  
- **Methodology**:  
  Data preparation (cleaning, normalization), splitting datasets (train/test/validation), cross-validation, interpretation of results.  

---

## 2. **Key Algorithms and Methods**  
### **Metric Methods**  
- **K-Nearest Neighbors (KNN)**:  
  Working with distance metrics (Euclidean, Manhattan), selecting the optimal number of neighbors (k), overfitting issues.  

### **Linear Models**  
- **Linear Regression**:  
  Minimizing MSE, gradient descent, regularization (L1/L2).  
- **Logistic Regression**:  
  Classification using the sigmoid function, probability estimation.  

### **Kernel Methods**  
- **Support Vector Machines (SVM)**:  
  Linear and nonlinear separators using kernel functions (RBF, polynomial).  

### **Decision Trees**  
- Tree construction: criteria (entropy, Gini), node splitting.  
- Combating overfitting: pruning, limiting depth.  

### **Ensemble Methods**  
- **Bagging**: Random Forest, model diversity.  
- **Boosting**: AdaBoost, Gradient Boosting, optimizing errors from previous models.  

---

## 3. **Model Evaluation**  
- **Classification Metrics**:  
  Accuracy, Precision, Recall, F1-score, ROC-AUC.  
- **Curve Interpretation**:  
  ROC curve, analyzing the trade-off between sensitivity and specificity.  
- **Hyperparameter Optimization**:  
  Grid Search, validation on a holdout set.  

---

## 4. **Unsupervised Learning**  
### **Clustering**  
- **K-Means**:  
  Centroid initialization, iterative optimization, evaluation using silhouette score.  
- **Hierarchical Clustering**:  
  Agglomerative methods, dendrograms.  

### **Dimensionality Reduction**  
- **Principal Component Analysis (PCA)**:  
  Extracting principal axes of variance, noise reduction.  
- **t-SNE and UMAP**:  
  Visualizing multidimensional data in 2D/3D.  

---

## 5. **Advanced Topics**  
### **Recommendation Systems**  
- Collaborative Filtering:  
  User-based and item-based approaches.  
- Matrix Decomposition:  
  SVD, matrix factorization.  

### **Neural Networks**  
- Basic Architecture:  
  Layers (fully connected, activation functions), backpropagation.  
- Applications:  
  Image classification, regression, basic principles of deep learning.  

---

## 6. **Practical Component**  
Each topic was reinforced with homework assignments, including:  
- **Theoretical Tests**:  
  Checking theoretical knowledge.  
- **Algorithm Implementation**:  
  Coding KNN, linear regression, PCA, Random Forest, K-means.  
- **Working with Real Data**:  
  Preprocessing, selecting metrics, optimizing hyperparameters.  

---

## ðŸŽ¯ Course Outcomes  
The course provided a systematic understanding of machine learning:  
- From simple metric methods to complex ensembles and neural networks.  
- The ability to choose algorithms for specific tasks.  
- Skills in evaluating and interpreting models.  
- Hands-on experience with libraries (e.g., Colab) and real-world datasets.  

- ðŸ”— Useful Links:
    - [Cource Link](https://github.com/MSUcourses/Data-Analysis-with-Python/tree/main/Machine%20Learning)


* ***Some Notebooks are not available, but will be added in the near future***

## Project Tree
```
â”œâ”€â”€ Binary_Classification_KNN_ML3_1.ipynb
â”œâ”€â”€ datasets
â”‚Â Â  â””â”€â”€ train6.csv
â”œâ”€â”€ DecisionTree_Classifier_ML6.ipynb
â”œâ”€â”€ Gradient_Descent_ML4_1.ipynb
â”œâ”€â”€ KNN_classifier_ML3_3.ipynb
â”œâ”€â”€ Lin_Reg_ML4_2.ipynb
â”œâ”€â”€ Log_Reg_ML2.ipynb
â”œâ”€â”€ README.md
â”œâ”€â”€ Select_Kern_ML5.ipynb
â”œâ”€â”€ Select_Metric_ML3_2.ipynb
â””â”€â”€ task6-2.py
```


